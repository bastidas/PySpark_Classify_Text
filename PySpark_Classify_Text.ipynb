{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict a classification tag for a body of text in a all vs one strategy. The final output is a file, classification.pkl, that contains a row tuple for each of the top 100 tags in the training data set: `(\"some tag name\", [prediction_values]*len(number of test cases))`\n",
    "* Uses PySpark and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[*]\", \"pyspark_df\")\n",
    "print sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import toolz\n",
    "import time\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET\n",
    "import mwparserfromhell\n",
    "import os\n",
    "import re\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import UserDefinedFunction as udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from datetime import datetime, date, time\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xml_encode(line):\n",
    "    try: \n",
    "        root = ET.fromstring(line.encode('utf-8'))\n",
    "    except:\n",
    "        return False\n",
    "    return root\n",
    "    \n",
    "    \n",
    "def tf_filter(x):\n",
    "    if x == False:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_posts = sc.textFile(\"train_dir\")\\\n",
    ".filter(lambda line: line.strip().startswith('<row'))\\\n",
    ".map(lambda x: xml_encode(x))\\\n",
    ".filter(lambda x: tf_filter(x))\\\n",
    ".map(lambda line: (line.get(\"Body\"),\n",
    "                   line.get(\"PostTypeId\"),\n",
    "                   line.get(\"Tags\")\n",
    "                  ))\\\n",
    ".filter(lambda x: x[1]=='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tags = train_posts.map(lambda x: str(x[2]).strip(\"<\").strip(\">\").split(\"><\"))\\\n",
    ".flatMap(lambda x: x)\\\n",
    ".map(lambda x: (x,1))\\\n",
    ".aggregateByKey(0,lambda x,y: x+y, lambda x,y: x+y)\\\n",
    ".filter(lambda x: x[0] != None)\\\n",
    ".map(lambda x: (x[1],x[0]))\\\n",
    ".sortByKey(ascending=False)\n",
    "top_tags = all_tags.take(110)\n",
    "top_tags_df = pd.DataFrame.from_records(top_tags, columns = [\"count\", \"tag\"])\n",
    "top_tags_df = top_tags_df.sort_values(by=['count', 'tag'], ascending=[False, True])\n",
    "top_tags = top_tags_df.tag.values[0:100]\n",
    "print top_tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_posts = sc.textFile(\"test_dir\")\\\n",
    ".filter(lambda line: line.strip().startswith('<row'))\\\n",
    ".map(lambda x: xml_encode(x))\\\n",
    ".filter(lambda x: tf_filter(x))\\\n",
    ".map(lambda line: (line.get(\"Body\"),\n",
    "                   line.get(\"PostTypeId\"),\n",
    "                   line.get(\"Tags\")\n",
    "                  ))\\\n",
    ".filter(lambda x: x[1]=='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_posts = train_posts.map(lambda x: (x[0], str(x[2]).strip(\"<\").strip(\">\").split(\"><\")))\n",
    "test_posts = test_posts.map(lambda x: (x[0], str(x[2]).strip(\"<\").strip(\">\").split(\"><\")))\n",
    "\n",
    "print train_posts.take(1)\n",
    "print test_posts.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_mapper(tag, tags):\n",
    "    if tag in tags:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_prediction_array =  [(x,[0.0]*len(test_posts)) for x in top_tags]\n",
    "\n",
    "n = 0\n",
    "for tag in top_tags:\n",
    "    print tag\n",
    "    one_label_train_posts = train_posts.map(lambda x: (x[0], tag_mapper(tag, x[1])))\n",
    "    training = sqlContext.createDataFrame(one_label_train_posts, [\"body\", \"label\"])\n",
    "\n",
    "    tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "    hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "    logreg = LogisticRegression(maxIter=25, regParam=0.03)# intercept=True )\n",
    "\n",
    "    tokens = tokenizer.transform(training)\n",
    "    hashes = hashingTF.transform(tokens)\n",
    "    model = logreg.fit(hashes)\n",
    "\n",
    "    one_label_test_posts = test_posts.map(lambda x: (x[0], tag_mapper(tag, x[1])))\n",
    "    testing = sqlContext.createDataFrame(one_label_test_posts, [\"body\", \"label\"])\n",
    "    \n",
    "    test_tokens = tokenizer.transform(testing)\n",
    "    test_hashes = hashingTF.transform(test_tokens)\n",
    "\n",
    "    prediction = model.transform(test_hashes)\n",
    "    probs = prediction.select(\"probability\").collect()\n",
    "    tag_probs = [p[0][1] for p in probs]\n",
    "    tag_prediction_array[n] = (tag,tag_probs)\n",
    "    n += 1\n",
    "    \n",
    "output = open(\"classification.pkl\", \"wb\")\n",
    "pickle.dump(tag_prediction_array, output)\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
